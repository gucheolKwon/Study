Fastcampus <br>
1) 파이썬으로 할수 있는 모든 것 with 47개 프로젝트 초격차 패키지 Online
- 웹 크롤링 관련 내용
- 웹 개발 프로젝트 - Fastapi를 활용해 이미지 저장 및 서빙하기 - FastAPI와 프로젝트 구성 및 셋팅 + DB 핸들링과 모델링 + 인증 미들웨어 만들기
- 파이썬 문법과 컴퓨터 기초 - 예외처리, 객체지향 프로그래밍, 알고리즘

2) 올인원 패키지 : 머신러닝 서비스 구축을 위한 실전 MLOps
- MLOps 환경 구축을 위한 도커와 쿠버네티스

3) 초격차 패키지 : 50개 프로젝트로 완벽하게 끝내는 머신러닝 SIGNATURE
- 실무 중심의 데이터 분석 방법 : Basic of Data Analytics - 머신러닝으로 접근하는 문제들
- 현업 문제해결 유형별 머신러닝 알고리즘 : eXplainable Method
- 반도체 웨이퍼 칩 Multi-output to Single-output 변환 분석 - 문제상황 및 프로세스 정의 및 Feature Engineering

<br><br><br><br> xAI 
활용처: 대량의 데이터로 학습이 가능하지만 동작원리와 학습과정을 명확히 설명하기 어려운 신경망 알고리즘
설명 시점: 현재 XAI에 대한 대부분의 논의는 모델이 만들어지고 난 이후에 설명(Post-hoc)하는 방법
필요 사항: 사후 설명해야 한다는 과정상의 특징으로 볼 때 학습에 사용된 알고리즘에 구애받지 않을 (Model-agnostic) XAI 방법이 필요
설명 방법
전역 설명(Global)
국소 설명(Local)
LIME (Local Interpretable Model-agnostic Explainations)
- 원본모델 학습에 사용된 원본 데이터를 근사하게 변형하여 학습했을 때 어떤 현상이 발생하는지를 조사하여 해당 모델의 특정 예측 결과를 설명
- 특정한 사건의 예측에 대해 유사한 데이터 값을 발생시키고 원본모델과 유사한 모델을 생성함으로써 원본모델이 특정 예측에 이르게 된 이유를 이해할 수 있도록 도와줄 수 있음
- 원본모델의 종류와 관계없이 개별 예측을 결과를 설명하기 위해서 사용할 수 있는 방법
- 이미지, 텍스트를 포함한 다양한 데이터에 대해 임의의 판별 인공지능 모델의 예측을 선형유사(linear approximation)로 설명
SHAP (SHapley Additive exPlanations) : 협력게임이론 중에서 각 게임 참여자에게 수익의 배당을 공정하게 배분하는 알고리즘인 Shapley Value를 기반으로 함. 
- 머신러닝 문제를 협력게임 문제로 비유하면, 예측값을 산출하는 알고리즘에 변수가 입력됐을 때, 각 입력변수가 예측값에 기여한 정도를 공정하게 측정한 결과를 찾는 것.
- 각종 데이터에 대응하는 인공지능 모델의 예측에 대해 특징량의 공헌도를 게임 이론적인 지표를 사용해 고르게 나누어 설명

Surrogate Model : 간단히 설정된 Rule을 기반으로 결정을 내려가는 알고리즘 유형. 계층 구조로 사용하는 결정 트리가 대표적인 모델 예시. 기본적으로 명확하게 설정된 규칙기반에서 결정을 내리기 때문에 사람이 쉽게 해석 가능
-  원본모델이 학습한 데이터를 사용하고, Linear Regression이나 Deicison Tree등과 같은 그 자체로 설명이 용이한 알고리즘을 사용해서 대리모델 생성.
-  모델 예측 결과에 대해 영향을 주는 변수를 설명해야 하기 때문에 -> 원본모델에서 산출된 예측 결과값을 가지고 근사한 결과가 산출되도록 모델을 학습
선형 모델 : 회귀시과 같은 선형 방정식을 사용하여 결과를 예측하는 알고리즘 유형

프로토타입 모델 : 기존에 있는 간단한 모형의 예시를 기반으로 하여 비교하여 결정을 내리는 유형
신경망 모델 : 인공지능이 학습하기 위한 기본적인 모델, 알고리즘. 해석이 어렵기 때문에 해석에 대한 LRP(Layer-wise Relevance Propagation) 및 심층 테일러 분해 (Deep Taylor Decomposition)을 이용해 해석
원본모델이 학습한 데이터를 사용
Linear Regression이나 Decision Tree 등과 같은 그 자체로 설명이 용이한 알고리즘을 사용하여 대리모델을 생성
원본모델에서 산출된 예측 결과값을 가지고 근사한 결과가 산출되도록 모델을 학습하는 과정
LIME(Local Interpretable Model-agnostic Explanations)
원본모델의 종류에 무관
학습 데이터의 유형에도 무관
하지만 특정 원본 데이터의 변형 데이터 생성 시 변수 간 상관관계를 고려하지 않으며 정규분포에서 샘플링하는 문제가 있고,
샘플링이 어떻게 되느냐에 따라 설명이 크게 달라지게 되는 일관성 유지의 문제가 있다고 지적받고 있음
SHAP(SHapley Additive exPlanations)
예측 결과를 산출하는 데 각 Feature가 얼마나 공헌했는지를 게임이론에서 각 플레이어의 기여도를 산출하는 기법
단순히 개별 Feature의 유무에 따른 영향도가 아니라 다른 Feature와의 관계까지 고려하고 있는 것이 이 방법의 장점
Feature를 이용하여 발생 가능한 모든 순열구조를 만든 후, 각 Feature의 가감을 통해 예측 값을 계산하면서 그 평균적인 영향을 Shapley Value로 표현
SHAP 라이브러리가 제공하는 시각화하는 기능을 사용 가능
모델의 특징을 일관성을 가지고 설명할 수 있다는 장점
각 Feature의 기여도를 계산하는 방식이 Feature 수의 지수만큼 계산량이 증가하는 특정이 있어 변수가 10~20개 수준을 넘어가는 모델의 설명 방법으로는 비추천
